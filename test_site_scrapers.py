#!/usr/bin/env python3
"""
Site Spesifik Scraper Test DosyasÄ±
Bu dosya verdiÄŸiniz linkler iÃ§in oluÅŸturulan scraper'larÄ± test eder.
"""

import asyncio
import json
import sys
import os
from site_specific_scrapers import SiteSpecificScrapers
from advanced_site_scrapers import AdvancedSiteScrapers

async def test_basic_scrapers():
    """Temel scraper'larÄ± test eder"""
    print("=== TEMEL SCRAPER TEST ===")
    scraper = SiteSpecificScrapers()
    
    test_urls = [
        "https://www.beymen.com/tr/p_polo-ralph-lauren-beyaz-oxford-gomlek_1646218",
        "https://www.ellesse.com.tr/products/ellesse-erkek-polo-yaka-tisort-em460-bk",
        "https://www.beyyoglu.com/100-keten-oversize-gomlek-24ss53005006-27/",
        "https://www.ninewest.com.tr/urun/nine-west-margarita-5fx-siyah-kadin-topuklu-sandalet-101928976",
        "https://www.levis.com.tr/levis-511-slim-fit_117340",
        "https://www.dockers.com.tr/smart-360-flex-ultimate-chino-slim-fit-pantolon_2661",
        "https://sarar.com/sarar-loreto-kot-elbise-18167",
        "https://www.salomon.com.tr/acs-plus-unisex-sneaker-l47705300",
        "https://www.abercrombie.com/shop/wd/p/premium-polished-tee-57648335?categoryId=12204&faceout=model&seq=13",
        "https://www.loft.com.tr/p/loose-fit-erkek-tshirt-kkol-6931",
        "https://ucla.com.tr/canary-haki-bisiklet-yaka-gofre-baskili-modal-kumas-standard-fit-erkek-tshirt",
        "https://www.yargici.com/kahverengi-regular-fit-keten-gomlek-p-198901"
    ]
    
    results = []
    for i, url in enumerate(test_urls, 1):
        print(f"\n[{i}/{len(test_urls)}] Scraping: {url}")
        try:
            result = await scraper.scrape_product(url)
            results.append(result)
            
            if "error" in result:
                print(f"âŒ Hata: {result['error']}")
            else:
                print(f"âœ… BaÅŸarÄ±lÄ±:")
                print(f"   Site: {result.get('site', 'N/A')}")
                print(f"   BaÅŸlÄ±k: {result.get('title', 'N/A')[:50]}...")
                print(f"   GÃ¼ncel Fiyat: {result.get('current_price', 'N/A')}")
                print(f"   Eski Fiyat: {result.get('original_price', 'N/A')}")
                print(f"   Resim: {result.get('image_url', 'N/A')[:50]}...")
            
        except Exception as e:
            print(f"âŒ Beklenmeyen hata: {e}")
            results.append({"error": str(e), "url": url})
        
        await asyncio.sleep(1)  # Rate limiting
    
    # SonuÃ§larÄ± kaydet
    with open("basic_scraping_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nðŸ“ Temel scraper sonuÃ§larÄ± basic_scraping_results.json dosyasÄ±na kaydedildi.")
    return results

async def test_advanced_scrapers():
    """GeliÅŸmiÅŸ scraper'larÄ± test eder"""
    print("\n=== GELÄ°ÅžMÄ°Åž SCRAPER TEST ===")
    scraper = AdvancedSiteScrapers()
    
    test_urls = [
        "https://www.beymen.com/tr/p_polo-ralph-lauren-beyaz-oxford-gomlek_1646218",
        "https://www.ellesse.com.tr/products/ellesse-erkek-polo-yaka-tisort-em460-bk",
        "https://www.beyyoglu.com/100-keten-oversize-gomlek-24ss53005006-27/",
        "https://www.ninewest.com.tr/urun/nine-west-margarita-5fx-siyah-kadin-topuklu-sandalet-101928976",
        "https://www.levis.com.tr/levis-511-slim-fit_117340",
        "https://www.dockers.com.tr/smart-360-flex-ultimate-chino-slim-fit-pantolon_2661",
        "https://sarar.com/sarar-loreto-kot-elbise-18167",
        "https://www.salomon.com.tr/acs-plus-unisex-sneaker-l47705300",
        "https://www.abercrombie.com/shop/wd/p/premium-polished-tee-57648335?categoryId=12204&faceout=model&seq=13",
        "https://www.loft.com.tr/p/loose-fit-erkek-tshirt-kkol-6931",
        "https://ucla.com.tr/canary-haki-bisiklet-yaka-gofre-baskili-modal-kumas-standard-fit-erkek-tshirt",
        "https://www.yargici.com/kahverengi-regular-fit-keten-gomlek-p-198901"
    ]
    
    results = []
    for i, url in enumerate(test_urls, 1):
        print(f"\n[{i}/{len(test_urls)}] Scraping: {url}")
        try:
            result = await scraper.scrape_product(url)
            results.append(result)
            
            if "error" in result:
                print(f"âŒ Hata: {result['error']}")
            else:
                print(f"âœ… BaÅŸarÄ±lÄ±:")
                print(f"   Site: {result.get('site', 'N/A')}")
                print(f"   BaÅŸlÄ±k: {result.get('title', 'N/A')[:50]}...")
                print(f"   GÃ¼ncel Fiyat: {result.get('current_price', 'N/A')}")
                print(f"   Eski Fiyat: {result.get('original_price', 'N/A')}")
                print(f"   Resim: {result.get('image_url', 'N/A')[:50]}...")
            
        except Exception as e:
            print(f"âŒ Beklenmeyen hata: {e}")
            results.append({"error": str(e), "url": url})
        
        await asyncio.sleep(1)  # Rate limiting
    
    # SonuÃ§larÄ± kaydet
    with open("advanced_scraping_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    print(f"\nðŸ“ GeliÅŸmiÅŸ scraper sonuÃ§larÄ± advanced_scraping_results.json dosyasÄ±na kaydedildi.")
    return results

async def test_single_url(url: str):
    """Tek bir URL'yi test eder"""
    print(f"\n=== TEK URL TEST: {url} ===")
    
    # Temel scraper ile test
    print("\n--- Temel Scraper ---")
    basic_scraper = SiteSpecificScrapers()
    try:
        result = await basic_scraper.scrape_product(url)
        if "error" in result:
            print(f"âŒ Temel scraper hatasÄ±: {result['error']}")
        else:
            print(f"âœ… Temel scraper baÅŸarÄ±lÄ±:")
            print(f"   Site: {result.get('site', 'N/A')}")
            print(f"   BaÅŸlÄ±k: {result.get('title', 'N/A')}")
            print(f"   GÃ¼ncel Fiyat: {result.get('current_price', 'N/A')}")
            print(f"   Eski Fiyat: {result.get('original_price', 'N/A')}")
            print(f"   Resim: {result.get('image_url', 'N/A')}")
    except Exception as e:
        print(f"âŒ Temel scraper beklenmeyen hata: {e}")
    
    # GeliÅŸmiÅŸ scraper ile test
    print("\n--- GeliÅŸmiÅŸ Scraper ---")
    advanced_scraper = AdvancedSiteScrapers()
    try:
        result = await advanced_scraper.scrape_product(url)
        if "error" in result:
            print(f"âŒ GeliÅŸmiÅŸ scraper hatasÄ±: {result['error']}")
        else:
            print(f"âœ… GeliÅŸmiÅŸ scraper baÅŸarÄ±lÄ±:")
            print(f"   Site: {result.get('site', 'N/A')}")
            print(f"   BaÅŸlÄ±k: {result.get('title', 'N/A')}")
            print(f"   GÃ¼ncel Fiyat: {result.get('current_price', 'N/A')}")
            print(f"   Eski Fiyat: {result.get('original_price', 'N/A')}")
            print(f"   Resim: {result.get('image_url', 'N/A')}")
    except Exception as e:
        print(f"âŒ GeliÅŸmiÅŸ scraper beklenmeyen hata: {e}")

def print_summary(basic_results, advanced_results):
    """Test sonuÃ§larÄ±nÄ±n Ã¶zetini yazdÄ±rÄ±r"""
    print("\n" + "="*50)
    print("TEST SONUÃ‡LARI Ã–ZETÄ°")
    print("="*50)
    
    # Temel scraper sonuÃ§larÄ±
    basic_success = sum(1 for r in basic_results if "error" not in r)
    basic_total = len(basic_results)
    print(f"\nðŸ“Š Temel Scraper:")
    print(f"   BaÅŸarÄ±lÄ±: {basic_success}/{basic_total} ({basic_success/basic_total*100:.1f}%)")
    
    # GeliÅŸmiÅŸ scraper sonuÃ§larÄ±
    advanced_success = sum(1 for r in advanced_results if "error" not in r)
    advanced_total = len(advanced_results)
    print(f"\nðŸ“Š GeliÅŸmiÅŸ Scraper:")
    print(f"   BaÅŸarÄ±lÄ±: {advanced_success}/{advanced_total} ({advanced_success/advanced_total*100:.1f}%)")
    
    # Hata analizi
    print(f"\nðŸ” Hata Analizi:")
    basic_errors = [r for r in basic_results if "error" in r]
    advanced_errors = [r for r in advanced_results if "error" in r]
    
    if basic_errors:
        print(f"   Temel scraper hatalarÄ±: {len(basic_errors)}")
        for error in basic_errors[:3]:  # Ä°lk 3 hatayÄ± gÃ¶ster
            print(f"     - {error.get('error', 'Bilinmeyen hata')}")
    
    if advanced_errors:
        print(f"   GeliÅŸmiÅŸ scraper hatalarÄ±: {len(advanced_errors)}")
        for error in advanced_errors[:3]:  # Ä°lk 3 hatayÄ± gÃ¶ster
            print(f"     - {error.get('error', 'Bilinmeyen hata')}")

async def main():
    """Ana test fonksiyonu"""
    print("ðŸš€ Site Spesifik Scraper Test BaÅŸlatÄ±lÄ±yor...")
    
    # Komut satÄ±rÄ± argÃ¼manlarÄ±nÄ± kontrol et
    if len(sys.argv) > 1:
        url = sys.argv[1]
        await test_single_url(url)
        return
    
    # TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r
    try:
        basic_results = await test_basic_scrapers()
        advanced_results = await test_advanced_scrapers()
        print_summary(basic_results, advanced_results)
        
        print(f"\nðŸŽ‰ Test tamamlandÄ±!")
        print(f"ðŸ“ SonuÃ§ dosyalarÄ±:")
        print(f"   - basic_scraping_results.json")
        print(f"   - advanced_scraping_results.json")
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Test kullanÄ±cÄ± tarafÄ±ndan durduruldu.")
    except Exception as e:
        print(f"\nâŒ Test sÄ±rasÄ±nda hata oluÅŸtu: {e}")

if __name__ == "__main__":
    # KullanÄ±m talimatlarÄ±
    if len(sys.argv) > 1 and sys.argv[1] in ["-h", "--help", "help"]:
        print("""
Site Spesifik Scraper Test AracÄ±

KullanÄ±m:
    python test_site_scrapers.py                    # TÃ¼m testleri Ã§alÄ±ÅŸtÄ±r
    python test_site_scrapers.py <URL>              # Tek URL test et
    
Ã–rnek:
    python test_site_scrapers.py
    python test_site_scrapers.py "https://www.beymen.com/tr/p_polo-ralph-lauren-beyaz-oxford-gomlek_1646218"
        """)
        sys.exit(0)
    
    asyncio.run(main())
